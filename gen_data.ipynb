{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0edabf-190a-4269-9f37-8c40ea6fdad4",
   "metadata": {},
   "source": [
    "# Generate daily summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07936e14-9290-47ee-9087-df2c81b9178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114dbb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.daily_update import collect_statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d7552-1216-4d9f-8b42-66b3101cfa8d",
   "metadata": {},
   "source": [
    "### Process 2022-04-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd4e0e-64b5-4683-801d-d4be921c0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.daily_update import get_historique_file\n",
    "\n",
    "\n",
    "data_path = os.listdir(\"data\")\n",
    "\n",
    "process_04_30 = [os.path.join(\"data\", file_name) for file_name in data_path if file_name.startswith(\"historique_stations_2022-04\")]\n",
    "\n",
    "#print(process_04_30)\n",
    "\n",
    "# Create full histo df\n",
    "histo_df = pd.concat([get_historique_file(file_path, has_name=True) \n",
    "                        for file_path in process_04_30[:5]], axis=0)\n",
    "\n",
    "histo_df = pd.concat([get_historique_file(file_path, has_name=True, has_code=True) \n",
    "                        for file_path in process_04_30[5:9]]+[histo_df], axis=0)\n",
    "\n",
    "histo_df = pd.concat([get_historique_file(file_path, has_code=True) \n",
    "                        for file_path in process_04_30[9:]]+[histo_df], axis=0)\n",
    "\n",
    "histo_df.sort_index(inplace=True)\n",
    "\n",
    "#histo_df.drop_duplicates(inplace=True)\n",
    "#histo_df.to_parquet(\"..\\data\\Summary_2022-04-30.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3980cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of entries with missing 'stationCode'\n",
    "histo_df[\"stationCode\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ec27e",
   "metadata": {},
   "source": [
    "#### Fill in missing `stationCode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ref = pd.read_csv(\"data\\\\station_info_2022-05-15.csv\",\n",
    "                            names= [\"stationCode\", \"stationName\", \"capacity\", \"station_geo\", \"operative\"],\n",
    "                            index_col=\"stationName\")\n",
    "\n",
    "station_ref.drop(columns=[\"capacity\", \"operative\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: using 'station_geo' since multiple stations can share the same 'stationName'\n",
    "prod_df = histo_df.merge(station_ref, left_on=\"station_geo\", right_on=\"station_geo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that all 'stationCode' are populated\n",
    "prod_df[\"stationCode_y\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54922b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whenever both columns are defined, they coincide...\n",
    "(prod_df[\"stationCode_x\"] != prod_df[\"stationCode_y\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9adb653",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"data\\\\Summary_2022-05-17.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'stationCode_x', rename 'stationCode_y'\n",
    "histo_df = prod_df.drop(columns=[\"stationCode_x\"]).rename(columns={\"date\":\"file_time\", \"stationCode_y\": \"stationCode\"}).set_index(\"file_time\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14374a",
   "metadata": {},
   "source": [
    "#### Save to parquet, under standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48573c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to parquet\n",
    "save_cols = [\"stationCode\", \"operative\", \"available_mechanical\", \"available_electrical\"]\n",
    "save_path = os.path.join(\"data\", \"Summary_2022-04-30.parquet\")\n",
    "\n",
    "histo_df[save_cols].to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"data\\\\Summary_2022-04-30.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187436e3-eb7e-4a26-a7d1-9653645f8dd1",
   "metadata": {},
   "source": [
    "### Process 2022-05-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c8146-fd0a-4ecb-bc01-17d52de820d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.daily_update import get_historique_file, get_status_df\n",
    "\n",
    "\n",
    "data_path = os.listdir(\"data\")\n",
    "\n",
    "histo_05_01 = [os.path.join(\"data\", file_name) for file_name in data_path if file_name.startswith(\"historique_stations_2022-05-01\")]\n",
    "\n",
    "status_05_01 = [os.path.join(\"data\", file_name) for file_name in data_path if file_name.startswith(\"station_status_2022-05-01\")]\n",
    "\n",
    "histo_df0 = pd.concat([get_historique_file(file_path, has_code=True) for file_path in histo_05_01], axis=0)\n",
    "\n",
    "histo_df1 = pd.concat([get_status_df(file_path, has_header=False) for file_path in status_05_01], axis=0)\n",
    "\n",
    "histo_df = pd.concat([histo_df0, histo_df1], axis=0)\n",
    "\n",
    "histo_df.sort_index(inplace=True)\n",
    "\n",
    "save_path = os.path.join(\"data\", \"Summary_2022-05-01.parquet\")\n",
    "histo_df.to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_path = os.path.join(\"data\", \"Summary_2022-05-01.parquet\")\n",
    "\n",
    "#pd.read_parquet(save_path).reset_index().rename(columns={\"date\":\"file_time\"}).set_index(\"file_time\").to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(\"data\", \"Summary_2022-05-01.parquet\")\n",
    "pd.read_parquet(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdad8f0",
   "metadata": {},
   "source": [
    "### Process 2022-05-02 and 2022-05-03 (no headers!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00226eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(\"2022-05-02\", \"2022-05-03\")\n",
    "\n",
    "for day in date_range:\n",
    "    date_str = day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    collect_statuses(date_str, has_header=False)\n",
    "    print(\"Completed: \", date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9329a0b",
   "metadata": {},
   "source": [
    "### Process 2022-05-04, with its specific issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d56a55",
   "metadata": {},
   "source": [
    "The issue with data from 2022-05-04 is a permutation (?) between the columns `available_mechanical` and `operative` (or something similar).\n",
    "\n",
    "The change happens between:\n",
    "* `station_status_2022-05-04_213207.csv`\n",
    "* `station_status_2022-05-04_213253.csv`\n",
    "\n",
    "NB: to find where the change happened, simply check a sudden change in the series of 'seconds' of file names (here from 07 to 53)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.daily_update import extract_enrich_data\n",
    "\n",
    "data_path = os.listdir(\"data\")\n",
    "\n",
    "status_05_04 = [os.path.join(\"data\", file_name) for file_name in data_path if file_name.startswith(\"station_status_2022-05-04\")]\n",
    "\n",
    "part_0 = [status for status in status_05_04 \n",
    "            if status <= os.path.join(\"data\",\"station_status_2022-05-04_213207.csv\")]\n",
    "part_1 = [status for status in status_05_04 \n",
    "            if status > os.path.join(\"data\",\"station_status_2022-05-04_213207.csv\")]\n",
    "\n",
    "histo_df0 = pd.concat([extract_enrich_data(file_path, has_header=False) for file_path in part_0], axis=0)\n",
    "\n",
    "histo_df1 = pd.concat([extract_enrich_data(file_path, has_header=False) for file_path in part_1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b71cdc",
   "metadata": {},
   "source": [
    "Checking which column corresponds to mechanical and which one corresponds to electrical..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac5fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_df0[histo_df0[\"stationCode\"]==\"12109\"].iloc[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6808555",
   "metadata": {},
   "source": [
    "##### Concatenate dataframes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dee2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import permute_cols_names\n",
    "\n",
    "#histo_df1 = permute_cols_names(histo_df1)\n",
    "\n",
    "histo_df = pd.concat([histo_df0, histo_df1], axis=0)\n",
    "\n",
    "save_path = os.path.join(\"data\", \"Summary_2022-05-04.parquet\")\n",
    "histo_df.to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88770b8",
   "metadata": {},
   "source": [
    "#### Quick checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(\"data\", \"Summary_2022-05-04.parquet\")\n",
    "pd.read_parquet(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_df[histo_df[\"stationCode\"]==\"12109\"].loc[\"2022-05-04 21:00\": \"2022-05-04 22:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2aeeb",
   "metadata": {},
   "source": [
    "### Process 2022-05-05 to 2022-05-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cafd166",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(\"2022-05-05\", \"2022-05-09\")\n",
    "\n",
    "for day in date_range:\n",
    "    date_str = day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    collect_statuses(date_str, has_header=False)\n",
    "    print(\"Completed: \", date_str)\n",
    "\n",
    "    save_path = os.path.join(\"data\", \"Summary_{}.parquet\".format(date_str))\n",
    "    aux_df = pd.read_parquet(save_path)\n",
    "\n",
    "    permute_cols_names(aux_df).to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2652d39",
   "metadata": {},
   "source": [
    "#### Quick checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6578dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(\"data\", \"Summary_2022-05-09.parquet\")\n",
    "aux_df = pd.read_parquet(save_path)\n",
    "\n",
    "aux_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66add79",
   "metadata": {},
   "source": [
    "### Process 2022-05-10 (from no headers to built in headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12802353",
   "metadata": {},
   "source": [
    "There is a specific change on 2022-05-10:\n",
    "* until `station_status_2022-05-10_111159.csv`, the csv file has no header (and there is a permutation among columns...)\n",
    "* from `station_status_2022-05-10_111230.csv`, the csv file has a header!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.daily_update import extract_enrich_data\n",
    "\n",
    "\n",
    "data_path = os.listdir(\"data\")\n",
    "\n",
    "status_05_10 = [os.path.join(\"data\", file_name) for file_name in data_path if file_name.startswith(\"station_status_2022-05-10\")]\n",
    "\n",
    "part_0 = [status for status in status_05_10 \n",
    "            if status <= os.path.join(\"data\",\"station_status_2022-05-10_111159.csv\")]\n",
    "part_1 = [status for status in status_05_10 \n",
    "            if status > os.path.join(\"data\",\"station_status_2022-05-10_111159.csv\")]\n",
    "\n",
    "histo_df0 = pd.concat([extract_enrich_data(file_path, has_header=False) for file_path in part_0], axis=0)\n",
    "\n",
    "histo_df1 = pd.concat([extract_enrich_data(file_path) for file_path in part_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b3b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import permute_cols_names\n",
    "\n",
    "histo_df0 = permute_cols_names(histo_df0).rename(columns={\"date\":\"time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce13d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b41b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_df = pd.concat([histo_df0, histo_df1], axis=0)\n",
    "\n",
    "histo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c26fab",
   "metadata": {},
   "source": [
    "#### Quick checks: continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A selection of stations:\n",
    "# 21209 - Montrouge, Molière - République\n",
    "# 2009 - Bourse\n",
    "# 14138 - Porte de Vanves\n",
    "\n",
    "histo_df[histo_df[\"stationCode\"]==\"14138\"].loc[\"2022-05-10 11:00\": \"2022-05-10 12:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f37f252",
   "metadata": {},
   "source": [
    "#### Saving file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9fb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(\"data\", \"Summary_2022-05-10.parquet\")\n",
    "histo_df.to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b027e",
   "metadata": {},
   "source": [
    "### Regular case (from 2022-05-11 onwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_range = pd.date_range(\"2022-05-11\", \"2022-05-17\")\n",
    "date_range = pd.date_range(\"2022-05-17\", \"2022-05-17\")\n",
    "\n",
    "for day in date_range:\n",
    "    date_str = day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    collect_statuses(date_str)\n",
    "    print(\"Completed: \", date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3d6637",
   "metadata": {},
   "source": [
    "### Compression for 2022-05-18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033bc60",
   "metadata": {},
   "source": [
    "NB: should be needed only once! Here simply for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402342db",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = \"2022-05-18\"\n",
    "\n",
    "file_name = \"Summary_{}.parquet\".format(date_str)\n",
    "file_path = os.path.join(\"data\", file_name)\n",
    "\n",
    "aux_df = pd.read_parquet(file_path)\n",
    "\n",
    "aux_df.to_parquet(file_path, compression=\"brotli\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
